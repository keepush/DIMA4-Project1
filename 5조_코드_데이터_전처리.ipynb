{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858e7b7c-8120-412a-b242-deead3cc8be6",
   "metadata": {},
   "source": [
    "설명\n",
    "- 각 코드의 작성자는 마크다운 셀의 가장 끝부분에 (이름)으로 작성함\n",
    "- 만일 이름이 쓰여 있지 않은 경우, 바로 위와 작성자가 동일하거나, 대주제의 작성자와 동일함을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37568ade-c0f1-495e-a30f-c71a521fbeb0",
   "metadata": {},
   "source": [
    "# 2개 데이터 병합 (김묘경)\n",
    "- 사용 데이터: ais 신호 정보와 선박 정보\n",
    "- 공통키: vsl id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71555f78-9218-448e-9b90-78f33674d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ais_info = pd.read_csv('./ais_for_waiting_area_add_draft.csv')\n",
    "print(ais_info.shape)\n",
    "\n",
    "ship_info = pd.read_csv('./VSL_INFO 결측치 정리.csv')\n",
    "print(ship_info.shape)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "ais_info['VSL_TIMESTAMP'] = pd.to_datetime(ais_info['VSL_TIMESTAMP'],format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502e4de-903b-4f0a-b9c7-e384482a68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ais + ship\n",
    "df = pd.merge(ais_info,ship_info)\n",
    "df['TRIP'] = list(np.full(df.shape[0],-1.0))\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7fe68-ec5e-4129-bd83-bbe42d15085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ais_ship_merge.csv', index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a31d5-5107-4550-acf3-1e70cde7a523",
   "metadata": {},
   "source": [
    "# 근접 항구간의 항해 제거 (김묘경) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44698b7-8e85-4cd1-966e-8ca41222d7b9",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ae808-f317-4d86-90dc-08f00d0460df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6b3e9-63e4-478a-816a-eaac02edf2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항구의 좌표가 담긴 csv\n",
    "port_df = pd.read_csv('./240603_all_port.csv') # ,sep = '\\t'\n",
    "port_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cce1da-3b40-4a51-9734-505ed8b54b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ais+선박정보 데이터 csv\n",
    "before_df = pd.read_csv('./ais_ship_merge.csv') \n",
    "print(before_df.shape)\n",
    "before_df['VSL_TIMESTAMP'] = pd.to_datetime(before_df['VSL_TIMESTAMP'],format='%Y-%m-%d %H:%M:%S')\n",
    "print(before_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf664857-c4b3-43d9-be90-c633e17e5ffe",
   "metadata": {},
   "source": [
    "## 근접항 여부 파악 및 제거하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21fde7-349d-42bc-b71d-e963e32e10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Drop_Near(port_info,merged_df,near):\n",
    "    temp_list = []\n",
    "    for i in ['CNSHA', 'SGSIN', 'KRBNP', 'HKHKG', 'KRPUS', 'KRINC']: \n",
    "        for j in range(1, port_df.shape[0]-1):\n",
    "            tt1 = abs(port_info[port_info['port']==i]['lat'].values[0] - port_info.iloc[j]['lat'])\n",
    "            tt2 = abs(port_info[port_info['port']==i]['lon'].values[0] - port_info.iloc[j]['lon'])\n",
    "            if tt1==0 and tt2==0: \n",
    "                continue\n",
    "            elif tt1<=near and tt2<=near:\n",
    "                temp_list.append((port_df.iloc[j]['port'],port_df[port_df['port']==i]['port'].values[0]))\n",
    "    print('근접항 수:',len(temp_list)) \n",
    "    #print(temp_list)\n",
    "\n",
    "    temp_100 = pd.DataFrame(columns=merged_df.columns)\n",
    "    for i in temp_list: \n",
    "        a = merged_df[merged_df['FROM_PORT_CD']==i[0]]\n",
    "        a = a[a['TO_PORT_CD']==i[1]]\n",
    "        temp_100 = pd.concat([temp_100,a])\n",
    "    new_df = merged_df.drop(index=temp_100.drop_duplicates().index.tolist())\n",
    "    print('제거 완료 후 남은 데이터:',new_df.shape)\n",
    "    # 파일로 저장 \n",
    "    new_df.to_csv(f'./keep_csv/{near}_drop_near_ports.csv', index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8a1a4-e893-43ae-bf22-41b242ec158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#near_list = [0.4,2,2.4,3]\n",
    "near_list = [2.2,2.6,2.8,3.2]\n",
    "for find_near in near_list:\n",
    "    Drop_Near(port_df,before_df,find_near)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31943c7-5740-4ba9-86e3-e6c546b45001",
   "metadata": {},
   "source": [
    "# 항해별로 분리하기 (김묘경)\n",
    "기준 : ais 신호가 도착항 근처에서 출발항 근처로 이동하게 되는 순간 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b24123-7075-49ea-8a49-ad15917e4b49",
   "metadata": {},
   "source": [
    "## ais 신호 간 좌표 비교 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cacdf15-fc27-4c44-84ed-2b75740f99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neareast_Check(standard,loc,num=1):\n",
    "    condition1 = standard-num <= loc\n",
    "    #print(condition1)\n",
    "    condition2 = loc <= standard+num\n",
    "    #print(condition2)\n",
    "    return condition1 and condition2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cf6d9-30a3-4428-a3cb-53031a879b22",
   "metadata": {},
   "source": [
    "## 항해 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9035bb-3a16-4ec5-97b7-32dd250be1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CutTrip(from_port_info,to_port_info,before_cut_df,real_df,trip, num=1):\n",
    "  for i in range(before_cut_df.shape[0]-1): # 1선박, 1출발항, 1도착항 df에 대해...\n",
    "    first = before_cut_df.iloc[i]\n",
    "    first_index = pd.DataFrame(before_cut_df.iloc[i]).T.index[0]\n",
    "    second = before_cut_df.iloc[i+1]\n",
    "    second_index = pd.DataFrame(before_cut_df.iloc[i+1]).T.index[0]\n",
    "\n",
    "\n",
    "    #first_condition1 = to_port_info['lat'].values[0]-1 <= first['LAT'] <= to_port_info['lat'].values[0]+1\n",
    "    #first_condition2 = to_port_info['lon'].values[0]-1 <= first['LON'] <= to_port_info['lon'].values[0]+1\n",
    "\n",
    "    #second_condition1 = from_port_info['lat'].values[0]-1 <= second['LAT'] <= from_port_info['lat'].values[0]+1\n",
    "    #second_condition2 = from_port_info['lon'].values[0]-1 <= second['LON'] <= from_port_info['lon'].values[0]+1\n",
    "\n",
    "    a = Neareast_Check(to_port_info['lat'].values[0],first['LAT'],num) and Neareast_Check(to_port_info['lon'].values[0],first['LON'],num)\n",
    "    b = Neareast_Check(from_port_info['lat'].values[0],second['LAT'],num) and Neareast_Check(from_port_info['lon'].values[0],second['LON'],num)\n",
    "    last_condition = a and b\n",
    "\n",
    "    #if first_condition1 and first_condition2 and second_condition1 and second_condition2 :\n",
    "    if last_condition:\n",
    "      # print(to_port['lat'].values[0],first['LAT'],'/',to_port['lon'].values[0],first['LON'])\n",
    "\n",
    "      real_df.at[first_index,'TRIP'] = trip\n",
    "      trip+=1\n",
    "      #print(i,'.',first_index)\n",
    "      if i >= before_cut_df.shape[0]-2:\n",
    "        real_df.at[second_index,'TRIP'] = trip\n",
    "    else:\n",
    "      real_df.at[first_index,'TRIP'] = trip\n",
    "      if i >= before_cut_df.shape[0]-2:\n",
    "        real_df.at[second_index,'TRIP'] = trip\n",
    "\n",
    "  return real_df,trip\n",
    "\n",
    "\n",
    "  # real_df['TRIP'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f21a923-ca25-419e-bedc-d6d5d52a9646",
   "metadata": {},
   "source": [
    "## 그룹핑된 선박 정보를 받아, 추가 그룹핑 및 위의 함수들을 진행 \n",
    "<전체 방식> \n",
    "1. 위에서 근접 항해를 제거한 데이터 사용 \n",
    "2. 항구좌표 데이터, 선박별로 그룹핑된 데이터, 원본 데이터, 가까움의 기준 거리 사용\n",
    "3. 선박별로 그룹핑 된 데이터에 대해 출발항 별로 그룹핑하고, 도착항 별로 그룹핑 진행\n",
    "4. 그룹핑 전의 데이터 프레임에 TRIP 컬럼 추가\n",
    "5. 항해 번호는 하나의 선박 당 1부터 시작하도록 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f3471-5655-4d29-80e2-2bf76a3443f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grouped_to_FROM(port_info,grouped_df,before_add_trip_df,num=1):\n",
    "  trip_count = 1 # 각 선박의 trip 수\n",
    "\n",
    "  # 출발항별로 그룹핑\n",
    "  one_ship_from_ports = grouped_df.groupby('FROM_PORT_CD')\n",
    "  for from_port, one_from_df in one_ship_from_ports:\n",
    "    from_port_info = port_info[port_info['port']==from_port] # 출발항의 정보\n",
    "\n",
    "    # 도착항별로 그룹핑\n",
    "    one_ship_to_ports = one_from_df.groupby('TO_PORT_CD')\n",
    "    for to_port, one_to_df in one_ship_to_ports:\n",
    "      to_port_info = port_info[port_info['port']==to_port] # 도착항의 정보\n",
    "      one_to_df.sort_values('VSL_TIMESTAMP',inplace=True)\n",
    "      before_add_trip_df,trip_count = CutTrip(from_port_info,to_port_info,one_to_df,before_add_trip_df,trip_count, num)\n",
    "      trip_count+=1\n",
    "  return before_add_trip_df\n",
    "\n",
    "# 선박 이름별로 그룹핑된 선박\n",
    "\n",
    "# 그룹핑 전의 데이터 프레임 필요함 , 해당 데이터 프레임에 TRIP 컬럼 추가 ()\n",
    "# df =\n",
    "# df['TRIP'] = list(np.full(df.shape[0],-1.0))\n",
    "\n",
    "# Grouped_to_FROM(grouped_df,before_grouped,before_add_trip_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc26bae-4933-4911-9334-19c39d5cdaab",
   "metadata": {},
   "source": [
    "## 실제 분리 실행 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c38fe-a1d5-467b-9bee-f4596e0b1564",
   "metadata": {},
   "source": [
    "### 가까움의 기준을 바꿔가며 분리 실행 및 저장 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c9672-c2d6-4faf-840d-204f94484ee2",
   "metadata": {},
   "source": [
    "#### 항해 분리 및 저장\n",
    "- 근접항 제거에서 저장했던 데이터를 불러와 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68401874-2afa-40bc-849c-138ec9d30923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# near_list = [0.4,2,2.4,3]\n",
    "near_list = [2.2,2.6,2.8,3.2]\n",
    "for find_near in near_list:\n",
    "    df = pd.read_csv(f'./keep_csv/{find_near}_drop_near_ports.csv')\n",
    "    grouped_ships = df.groupby('VSL_ID')\n",
    "    save_df = pd.DataFrame(columns=df.columns)\n",
    "    count = 1\n",
    "    for name, one_df in grouped_ships:\n",
    "      one_df.sort_values('VSL_TIMESTAMP',inplace=True)\n",
    "      save_df = Grouped_to_FROM(port_df,one_df,df,find_near/2)\n",
    "      count+=1\n",
    "      if count%100 == 0:\n",
    "        save_df.to_csv(f'./last_csv/{find_near}_{find_near/2}_add_trip.csv', index=False,encoding='utf-8-sig')\n",
    "        print(count)\n",
    "      #cut_trip_df = Grouped_to_FROM(port_df,one_df,df)\n",
    "      save_df = pd.concat([save_df,cut_trip_df])\n",
    "   save_df.to_csv(f'./last_csv/{find_near}_{find_near/2}_add_trip.csv', index=False,encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb2e8c-85c9-44c9-9159-6d1a9a21cc7f",
   "metadata": {},
   "source": [
    "#### 각 분리 기준에 따른 항해 수 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc71281-a550-40d4-ac26-8067d213054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_recode = []\n",
    "for near in near_list: \n",
    "    last_recode_df = pd.read_csv(f'./last_csv/{near}_{near/2}_last_recode.csv')\n",
    "    print(near,'전체 마지막 레코드 수(항해 수):',last_recode_df.shape)\n",
    "    keep_recode.append(last_recode_df.shape[0])\n",
    "    #all_loc = [(one_port_df.iloc[i]['LAT'],one_port_df.iloc[i]['LON']) for i in range(one_port_df.shape[0])]\n",
    "    #all_lat = [one_port_df.iloc[i]['LAT'] for i in range(one_port_df.shape[0])]\n",
    "    #all_lon = [one_port_df.iloc[i]['LON'] for i in range(one_port_df.shape[0])]\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370f6ce-a687-4f9b-8365-63eed69bbc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.arange(0,20)\n",
    "#y = x*2  \n",
    "\n",
    "x_ticks = near_list #x축의 눈금을 표시할 index값\n",
    "plt.bar(np.arange(0,14),keep_recode,width=0.5) #label: 막대의 이름\n",
    "plt.xlabel('drop_near_size')\n",
    "plt.ylabel('trips')\n",
    "#plt.title('Bar Chart Example')\n",
    "plt.xticks(np.arange(0,14),x_ticks)\n",
    "#plt.yticks(np.arange(0,2700,100))\n",
    "plt.ylim(2000,2600)\n",
    "plt.grid(True,axis='y')\n",
    "#plt.legend() #막대의 이름을 적은 범례를 출력하게 하기 위함\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f8f3c-4f00-4c4d-a9dc-96ef986c8813",
   "metadata": {},
   "source": [
    "# 신호가 없는 기간이 길면 삭제 (김묘경)\n",
    "조건 : 도착항의 평균 대기 시간 이상 길면 제거 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c387927-4a61-444f-8764-0ae5d39bd9d1",
   "metadata": {},
   "source": [
    "## 데이터 파악 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add93d5e-cb73-4408-8dcb-9dff6633e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# ['CNSHA', 'SGSIN', 'KRBNP', 'HKHKG', 'KRPUS', 'KRINC']\n",
    "df = pd.read_csv('2.2_1.1_add_trip.csv') \n",
    "print(df.shape) \n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47aa447-368b-405d-8375-b12bce66c612",
   "metadata": {},
   "source": [
    "## 항해 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84716247-e722-48c9-95ec-7669b791634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항구별 평균 대기 시간 \n",
    "waithing = {'CNSHA':28, \n",
    " 'SGSIN':9.73, \n",
    " 'KRBNP':11.07, \n",
    " 'HKHKG':5.4, \n",
    " 'KRPUS':31, \n",
    " 'KRINC':24}\n",
    "to_ports = ['CNSHA', 'SGSIN', 'KRBNP', 'HKHKG', 'KRPUS', 'KRINC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139ada0-399f-478b-8850-86011e8c4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체항이 저장됨 \n",
    "save_df = pd.DataFrame(columns = df.columns) \n",
    "# 도착항별 그룹핑\n",
    "for to_port, port_df in df.groupby('TO_PORT_CD'):\n",
    "    # 각 항구별 저장 (문서 저장을 위함)\n",
    "    one_port_df = pd.DataFrame(columns = port_df.columns)\n",
    "    # 선박별 그룹핑\n",
    "    for vsl_id, one_ship in port_df.groupby('VSL_ID'):\n",
    "        # 각 선박별 저장 (trip값 변경을 위함)\n",
    "        one_ship_df = pd.DataFrame(columns = one_ship.columns)\n",
    "        # 항해별 그룹핑\n",
    "        for name, trip in one_ship.groupby('TRIP'): \n",
    "            # 시계열로 변경\n",
    "            trip['VSL_TIMESTAMP'] = pd.to_datetime(trip['VSL_TIMESTAMP'],format='%Y-%m-%d %H:%M:%S')\n",
    "            # 시계열 순서대로 정렬\n",
    "            trip = trip.sort_values('VSL_TIMESTAMP')\n",
    "            # 1개 항해에 대해 반복\n",
    "            for i in range(trip.shape[0]-1): \n",
    "                # i+1번째 시간 - i번째 시간 \n",
    "                sub = trip.iloc[i+1]['VSL_TIMESTAMP'] - trip.iloc[i]['VSL_TIMESTAMP']\n",
    "                # 시간 텀이 sub 이상 존재 => 저장 안함 \n",
    "                if sub > timedelta(days=waithing[to_port]): \n",
    "                    break\n",
    "                # 마지막 항해라면 \n",
    "                if i == trip.shape[0]-2:\n",
    "                    # 정상적 항해 저장\n",
    "                    one_ship_df = pd.concat([one_ship_df,trip])\n",
    "        encoded = LabelEncoder().fit_transform(one_ship_df['TRIP'])\n",
    "        one_ship_df['TRIP'] = encoded\n",
    "        # 선박별 저장용 df에 추가\n",
    "        one_port_df = pd.concat([one_port_df,one_ship_df])\n",
    "    print(f'{to_port}항 완료')\n",
    "    # 항해 순서값 정렬\n",
    "    one_port_df.to_csv(f'2.2_{to_port}_drop_outlier.csv', index=False,encoding='utf-8-sig')\n",
    "    # 항구별 저장용 df에 추가\n",
    "    save_df = pd.concat([save_df,one_port_df])\n",
    "save_df.to_csv(f'2.2_all_drop_outlier.csv', index=False,encoding='utf-8-sig')\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a541a8a-d821-4f10-acd3-a6d9e53fe547",
   "metadata": {},
   "source": [
    "# 기상 데이터 수집\n",
    "1. 스크래핑으로 수집 \n",
    "    - 수집 예정 데이터 : 풍속, 해류, 파고\n",
    "    - 스크래핑 진행 사이트 : https://earth.nullschool.net/\n",
    "    - 사용한 파일 : ALL_COORDS_in_actual_waiting_df.csv\n",
    "      - 김정수님이 만들어주신 최초 시점+마지막 시점 병합 데이터 \n",
    "    \n",
    "    - 스크래핑 코드 작성자 \n",
    "      - 풍속 : 김묘경 작성 \n",
    "      - 해류 : 유지민 작성 \n",
    "      - 파고 : 곽현수 작성\n",
    "2. GAPCO 데이터 파일로 수집 (유지민)\n",
    "   - 수집 데이터 : 수심 \n",
    "\n",
    "- **주의사항**\n",
    "- 데이터를 분리하여 3여개 파일로 생성, 기상 수집을 동시 수행 하였기에 불러온 파일 오류 발생 가능성 있음\n",
    "  - ALL_COORDS_in_actual_waiting_df.csv.csv 파일을 5개로 분리하여 각각 ['first', 'second', 'third', 'fourth', 'fifth'].csv로 저장한 이후 실행하였음 \n",
    "- 스크래핑 후에도 존재하는 결측치는 분담하여 일일히 채웠음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757ea4c-51c8-400a-a54f-1280e5a9d109",
   "metadata": {},
   "source": [
    "## 스크래핑 함수  (곽현수, 김묘경, 유지민) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc936a57-fc89-438f-9ca5-b36128cc198e",
   "metadata": {},
   "source": [
    "### 데이터 호출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584cf6e-d1c5-4ece-b35a-dfac46e73cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import requests\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "\n",
    "#페이지가 로드될 때까지 기다리는 시간 (하이퍼 파라미터 사용)\n",
    "tum = 1.5 #sleep 시간을 일괄적으로 관리하기 위함\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09ebc3-5a27-4c7f-95bd-25804da0bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.read_csv('ALL_COORDS_in_actual_waiting_df.csv') \n",
    "df.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811d44f-0718-4fcb-9e35-18fd7eed7c4c",
   "metadata": {},
   "source": [
    "### 단위 변환 함수 (곽현수, 김묘경) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed9edb-bc72-4e4f-aa69-f6287012c299",
   "metadata": {},
   "source": [
    "### 풍속 스크래핑  (김묘경) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b998f227-207c-48bd-9d13-2d16b50787c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_Wind_SPEED(driver,year,month,day,hour,minute,lat,lon,PAUSE_TIME=1): \n",
    "    try:\n",
    "        URL = f'https://earth.nullschool.net/#{year}/{month}/{day}/'\n",
    "        set_time = hour \n",
    "        if minute>30: \n",
    "            set_time+=1 \n",
    "        URL = URL+f'{set_time}00Z/wind/surface/level/loc={lon:.3f},{lat:.3f}'\n",
    "        driver.get(URL)\n",
    "    \n",
    "        time.sleep(PAUSE_TIME) #동적으로 생성되는 페이지의 내용이 완성될 때 까지 대기\n",
    "        get_unit = driver.find_element(By.XPATH,'//*[@id=\"spotlight-panel\"]/div[2]/button/span[1]').text.strip() # 속도 방식 kn, km/h 등 \n",
    "        last = driver.find_element(By.XPATH,'//*[@id=\"spotlight-panel\"]/div[2]/div').text.split('@')[1].strip()\n",
    "        wind_speed = Change_Unit_to_kn(last,get_unit)\n",
    "        #soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "        #soup.select_one('#spotlight-panel > div:nth-child(2) > div').text.split('@')[1].strip()\n",
    "    \n",
    "        # driver.close() #실행되었던 웹드라이버 페이지 종료\n",
    "        return wind_speed\n",
    "    except Exception as e:\n",
    "        print(e,':',URL)\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eedf03f-48d1-4837-8d86-918677c71419",
   "metadata": {},
   "source": [
    "### 파고 스크래핑 (곽현수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f9795-d242-43c0-836b-3e6e4f9849b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_Wave_Height(driver,year,month,day,hour,minute,lat,lon,PAUSE_TIME=1): \n",
    "    try:\n",
    "        URL = f'https://earth.nullschool.net/#{year}/{month}/{day}/'\n",
    "        set_time = hour\n",
    "        if hour < 0 or hour >= 24:\n",
    "            #print('Wrong hour data')\n",
    "            pass\n",
    "        else:\n",
    "            hour = (hour // 3) * 3\n",
    "\n",
    "        URL = URL+f'{set_time}00Z/ocean/primary/waves/overlay=significant_wave_height/loc={lon:.3f},{lat:.3f}'\n",
    "        driver.get(URL)\n",
    "    \n",
    "        time.sleep(PAUSE_TIME) #동적으로 생성되는 페이지의 내용이 완성될 때 까지 대기\n",
    "        get_unit = driver.find_element(By.XPATH,'//*[@id=\"spotlight-panel\"]/div[3]/button/span[1]').text.strip() # 속도 방식 kn, km/h 등 \n",
    "        last = driver.find_element(By.XPATH,'//*[@id=\"spotlight-panel\"]/div[3]/div').text.strip()\n",
    "        wave_height = Change_Unit_to_m(last,get_unit)\n",
    "        if wave_height > 2: \n",
    "            print('파고 체크',wave_height,'m :',URL)\n",
    "        return wave_height\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('추출 불가 :',URL)\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb45f6a-ad3f-49a7-a4fa-05dc0613b26a",
   "metadata": {},
   "source": [
    "### 해류 스크래핑 (유지민) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2080e-2fdc-40a7-8771-a8b83aee51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_OCEAN_CURRENT(driver,year,month,day,lat,lon,PAUSE_TIME=1): \n",
    "    try:\n",
    "        URL = f'https://earth.nullschool.net/#{year}/{month}/{day}/0000Z/ocean/surface/currents/loc={lon:.3f},{lat:.3f}'\n",
    "        driver.get(URL)\n",
    "    \n",
    "        time.sleep(PAUSE_TIME) #동적으로 생성되는 페이지의 내용이 완성될 때 까지 대기\n",
    "        get_unit = driver.find_element(By.XPATH,'//*[@id=\"spotlight-panel\"]/div[2]/button/span[1]').text.strip() # 속도 방식 kn, km/h 등\n",
    "        last = driver.find_element(By.XPATH,'//*[@id=\"spotlight-panel\"]/div[2]/div').text.split('@')[1].strip()\n",
    "        ocean_current = Change_Unit_to_kn(last,get_unit)\n",
    "        if ocean_current > 2.5: \n",
    "            print('해류 체크',ocean_current,'kn :',URL)\n",
    "        return ocean_current\n",
    "    except Exception as e:\n",
    "        print('추출 불가 :',URL)\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec42dd-264d-4902-9e26-5774f3cd9869",
   "metadata": {},
   "source": [
    "### 실제 스크래핑 진행 함수  (김묘경)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda59721-33fc-4527-9d46-f323219cd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrapping(key,data_frame,P_T=1):\n",
    "    options = Options()\n",
    "    #options.add_argument('--headless')  # 화면 생성이 일어나지 않음 \n",
    "    #options.add_argument('--disable-gpu') #GPU 하드웨어 가속을 비활성화. 헤드리스 모드에서 발생할 수 있는 GPU 관련 문제를 피하기 위해 사용\n",
    "    dd = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    #['VSL_ID', 'TRIP', 'WAITING_ORDER', 'LAT', 'LON', 'WAITING_START','WAITING_END', 'WAITING_TIME(H:M:S)', 'START_LAT', 'START_LON','END_LAT', 'END_LON', 'TO_PORT_CD']\n",
    "    for i in range(data_frame.shape[0]):\n",
    "        for j in ['START','END']:\n",
    "            # try:\n",
    "            #     if data_frame.iloc[i][j+'_WIND(kn)']==-1 or data_frame.iloc[i][j+'_WIND(kn)']==0:\n",
    "            #         data_frame.at[i,j+'_WIND(kn)'] = GET_Wind_SPEED(dd,\n",
    "            #                                                         data_frame.iloc[i]['WAITING_'+j].year,data_frame.iloc[i]['WAITING_'+j].month,data_frame.iloc[i]['WAITING_'+j].day,\n",
    "            #                                                         data_frame.iloc[i]['WAITING_'+j].hour,data_frame.iloc[i]['WAITING_'+j].minute,\n",
    "            #                                                         data_frame.iloc[i][j+'_LAT'],data_frame.iloc[i][j+'_LON'],\n",
    "            #                                                         PAUSE_TIME=P_T)\n",
    "            # except Exception as e:\n",
    "            #     #print('기타 에러:',e)\n",
    "            #     pass\n",
    "            \n",
    "            #try:\n",
    "            if data_frame.iloc[i][j+'_CURRENT(kn)']==-1 or data_frame.iloc[i][j+'_CURRENT(kn)']==0 or data_frame.iloc[i][j+'_CURRENT(kn)']>=2:\n",
    "                current = GET_OCEAN_CURRENT(dd,\n",
    "                                            data_frame.iloc[i]['WAITING_'+j].year,data_frame.iloc[i]['WAITING_'+j].month,data_frame.iloc[i]['WAITING_'+j].day,\n",
    "                                            data_frame.iloc[i][j+'_LAT'],data_frame.iloc[i][j+'_LON'],\n",
    "                                            PAUSE_TIME=P_T)\n",
    "                data_frame.at[i,j+'_CURRENT(kn)'] = current \n",
    "            #print('해류:',current,'kn')\n",
    "            # except Exception as e:\n",
    "            #     #print('기타 에러:',e)\n",
    "            #     pass\n",
    "        \n",
    "            #try:\n",
    "            if data_frame.iloc[i][j+'_WAVE(m)']==-1 or data_frame.iloc[i][j+'_WAVE(m)']==0 or data_frame.iloc[i][j+'_WAVE(m)']>=1.5:\n",
    "                wave = GET_Wave_Height(dd,\n",
    "                                       data_frame.iloc[i]['WAITING_'+j].year,data_frame.iloc[i]['WAITING_'+j].month,data_frame.iloc[i]['WAITING_'+j].day,\n",
    "                                       data_frame.iloc[i]['WAITING_'+j].hour,data_frame.iloc[i]['WAITING_'+j].minute,\n",
    "                                       data_frame.iloc[i][j+'_LAT'],data_frame.iloc[i][j+'_LON'],\n",
    "                                       PAUSE_TIME=P_T)\n",
    "                data_frame.at[i,j+'_WAVE(m)'] = wave\n",
    "                #print('파고:',wave,'m')\n",
    "            # except Exception as e:\n",
    "            #     #print('기타 에러:',e)\n",
    "            #     pass\n",
    "\n",
    "        if i % 30 == 0: \n",
    "            print('over',i)\n",
    "            #print(data_frame.shape)\n",
    "            data_frame.to_csv(f'cuted_{key}.csv',index=False,encoding='utf-8-sig')\n",
    "    data_frame.to_csv(f'cuted_{key}.csv',index=False,encoding='utf-8-sig')\n",
    "    dd.close()\n",
    "    print(f'{key} 종료')\n",
    "    print('풍속 결측치:',data_frame[data_frame['START_WIND(kn)']==-1].shape[0]+data_frame[data_frame['END_WIND(kn)']==-1].shape[0],'개')\n",
    "    print('해류 결측치:',data_frame[data_frame['START_CURRENT(kn)']==-1].shape[0]+data_frame[data_frame['END_CURRENT(kn)']==-1].shape[0],'개')\n",
    "    print('파고 결측치:',data_frame[data_frame['START_WAVE(m)']==-1].shape[0]+data_frame[data_frame['END_WAVE(m)']==-1].shape[0],'개')\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20fb8ee-0c29-4691-86f0-1b8fe4b09833",
   "metadata": {},
   "source": [
    "### 스크래핑 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be29877-7913-43ce-9b29-bf0d9dc7d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['first', 'second', 'third', 'fourth', 'fifth']: \n",
    "    new = pd.read_csv(f'{i}.csv')\n",
    "    new['WAITING_START'] = pd.to_datetime(new['WAITING_START'],format='%Y-%m-%d %H:%M:%S')\n",
    "    new['WAITING_END'] = pd.to_datetime(new['WAITING_END'],format='%Y-%m-%d %H:%M:%S')\n",
    "    print(i,':',new.shape)\n",
    "    print(new.columns)\n",
    "    Scrapping(i,new,tum)\n",
    "    print('='*100)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca64abe-3b1e-4418-911b-83e5700292d3",
   "metadata": {},
   "source": [
    "## 수심 추출 (유지민) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47758c7c-317a-4a2d-9c79-2bc590d3b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a9592-3cf4-4b0e-8037-4625f6ae3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dd68d-abec-43d4-98c1-95f8f0d5a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda7769-a5f6-46c1-93f3-1a168b1741e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "file = r\"C:\\Users\\0\\Desktop\\GEBCO_2023\\GEBCO_2023.nc\"\n",
    "fdata = nc.Dataset(file)\n",
    "print(fdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f77e2-25ca-42bb-a727-f01827faf221",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\0\\Desktop\\GEBCO_2023\\GEBCO_2023.nc\"\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f7718-d5c7-4cc4-9f78-9b6d0d4037c9",
   "metadata": {},
   "source": [
    "## 특정 좌표의 수심 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad6d06-054c-4728-80e5-390c6fbf7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('df_add_trip_waiting_before_arrive.csv')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374a378-dec7-4462-81ed-0ae156c568aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADD_OCEAN_HEIGHT(latitude,longtitude): \n",
    "    # NetCDF 파일 열기 (예제 파일 경로를 사용하세요)\n",
    "    nc_file = r\"C:/Users/user/Desktop/GEBCO_2023/GEBCO_2023.nc\"\n",
    "    dataset = xr.open_dataset(nc_file)\n",
    "    \n",
    "    # 고도 데이터 변수 선택 (예: 'elevation' 변수)\n",
    "    elevation = dataset['elevation']\n",
    "    \n",
    "    # 관심 영역의 부분집합 선택\n",
    "    subset = elevation.sel(lat=slice(20, 50), lon=slice(100, 150))\n",
    "    \n",
    "    # 데이터 나누기\n",
    "    chunks = {'lat': 1000, 'lon': 1000}\n",
    "    subset = subset.chunk(chunks)\n",
    "    \n",
    "    # 데이터 축소 (여기서는 20x 축소)\n",
    "    subset_reduced = subset.coarsen(lat=20, lon=20, boundary='trim').mean()\n",
    "    \n",
    "    # 좌표에서 가장 가까운 셀의 고도 값을 선택\n",
    "    elevation_value = subset_reduced.sel(lat=latitude, lon=longtitude, method='nearest').compute()\n",
    "\n",
    "    return elevation_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81c6d2-1e00-4d64-a812-876d7a65bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "df = pd.read_csv('please_fill_nan4.csv') \n",
    "df['START_HEIGHT'] = list(np.full((df.shape[0]),None))\n",
    "df['END_HEIGHT'] = list(np.full((df.shape[0]), None))\n",
    "for i in range(df.shape[0]): \n",
    "    df.at[i,'START_HEIGHT'] = ADD_OCEAN_HEIGHT(df.at[i,'START_LAT'],df.at[i,'START_LON'])\n",
    "    df.at[i,'END_HEIGHT'] = ADD_OCEAN_HEIGHT(df.at[i,'END_LAT'],df.at[i,'END_LON'])\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de640f98-b044-468e-a644-b85b852213a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head()) \n",
    "print(df.isna().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb32fc-89f5-405d-86ea-d7cedb39e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['HEIGHT'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fff2b2-e0e4-47ba-a9b6-2004dd44ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('plz_fill_nan4.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b0f2b-20ed-405e-9e47-3d26c8f22b4f",
   "metadata": {},
   "source": [
    "# 파일에 존재하던 오류 해결 (김묘경)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044726dd-8483-49b8-8c8a-223f8dd734e1",
   "metadata": {},
   "source": [
    "## 1. 시간의 초가 삭제된 문제 해결 \n",
    "- 아래 데이터 들은 기상 정보를 추가하여 생성한 데이터를 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba23300-1a76-46be-b835-121898c651b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "a = pd.read_csv('aaa(수정).csv') \n",
    "print(a.shape)\n",
    "b = pd.read_csv('bbb(수정).csv')\n",
    "print(b.shape)\n",
    "c = pd.read_csv('ccc.csv')  \n",
    "print(c.shape)\n",
    "d = pd.read_csv('ddd.csv')\n",
    "print(d.shape)\n",
    "\n",
    "temp1 = pd.read_csv('KRINC_ALL_DATA.csv')\n",
    "print(temp1.shape)\n",
    "temp2 = pd.read_csv('CNSHA_ALL_DATA.csv')\n",
    "print(temp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8301b18-4ff9-4df2-9590-892a70cb5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([a,b,c,d,temp1,temp2])\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['START_LAT'] = df['START_LAT'].apply(lambda x:np.round(x,6))\n",
    "df['START_LON'] = df['START_LON'].apply(lambda x:np.round(x,6))\n",
    "df['END_LAT'] = df['END_LAT'].apply(lambda x:np.round(x,6))\n",
    "df['END_LON'] = df['END_LON'].apply(lambda x:np.round(x,6))\n",
    "df['WAIT_LAT'] = df['WAIT_LAT'].apply(lambda x:np.round(x,6))\n",
    "df['WAIT_LON'] = df['WAIT_LON'].apply(lambda x:np.round(x,6))\n",
    "\n",
    "df = df.rename(columns={'WAITING_START': 'ws','WAITING_END':'we'})\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ff2f6-5fa0-436f-906d-295a15871fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 선박명과 trip값을 가진 경우가 존재하는지 파악 함 \n",
    "for ship, ship_df in df.groupby('VSL_ID'): \n",
    "    for trip, trip_df in ship_df.groupby('TRIP'): \n",
    "        if trip_df.shape[0] >=2: \n",
    "            print(trip)\n",
    "            display(trip_df)\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5e7b4-2c2b-49d7-a4fb-8fb67399f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "former = pd.read_csv('please_fill_nan.csv')\n",
    "former['START_LAT'] = former['START_LAT'].apply(lambda x:np.round(x,6))\n",
    "former['START_LON'] = former['START_LON'].apply(lambda x:np.round(x,6))\n",
    "former['END_LAT'] = former['END_LAT'].apply(lambda x:np.round(x,6))\n",
    "former['END_LON'] = former['END_LON'].apply(lambda x:np.round(x,6))\n",
    "former.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6ac55-7629-48f1-9b2c-a03baf604b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "re = former[['VSL_ID', 'TRIP','WAITING_TIME(H:M:S)','START_LAT','START_LON','END_LAT','END_LON','WAITING_START','WAITING_END']]\n",
    "#re.loc[:, 'TRIP'] = re['TRIP'].astype(float)\n",
    "re['TRIP'] = re['TRIP'].apply(lambda x:float(x)) #np.round(x,1)\n",
    "re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc234b7-9a7f-44fc-bddb-c54ffe56d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined'] = df['VSL_ID'].astype(str) + '_' + df['TRIP'].astype(str) + '_' + df['WAITING_TIME(H:M:S)'].astype(str)\n",
    "re['combined'] = re['VSL_ID'].astype(str) + '_' + re['TRIP'].astype(str) + '_' + re['WAITING_TIME(H:M:S)'].astype(str)\n",
    "re = re[['WAITING_START','WAITING_END','combined']]\n",
    "test = pd.merge(df,re,on='combined',how='left')\n",
    "print(test.shape)\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4ba84-1ab5-4715-9fb3-7a0958e24652",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('ws',axis=1,inplace=True)\n",
    "test.drop('we',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb725606-f7a2-41ef-b173-62658e8efa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test[['TO_PORT_CD','VSL_ID', 'TRIP', 'WAITING_TIME(H:M:S)','WAIT_LAT', 'WAIT_LON',\n",
    "          'WAITING_START','START_LAT','START_LON', 'START_WAVE(m)', 'START_WIND(kn)', 'START_CURRENT(kn)','START_HEIGHT',\n",
    "          'WAITING_END','END_LAT', 'END_LON', 'END_WAVE(m)', 'END_WIND(kn)', 'END_CURRENT(kn)','END_HEIGHT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a628357-79e1-42fe-81d8-5c50a5309bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('0612_1297with_fix_timestamp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692144b-84f3-4f81-a322-b1d34a2766af",
   "metadata": {},
   "source": [
    "## 2. 드래프트 추가 \n",
    "- 동일한 타임스탬프를 가진 때를 찾아 드래프트를 추가하도록 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9246d-e988-4cc8-8b30-d89d0dd89fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = pd.read_csv('ais_for_waiting_area.csv')\n",
    "origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b4569-a23a-4e76-9c57-91af29fc36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = origin[['FROM_PORT_CD','VSL_ID','LAT','LON','VSL_DRAFT','VSL_SPEED','VSL_TIMESTAMP']]\n",
    "rr.loc[:,'LAT'] = rr['LAT'].apply(lambda x:np.round(x,6))\n",
    "rr.loc[:,'LON'] = rr['LON'].apply(lambda x:np.round(x,6))\n",
    "rr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d959b-96bf-4c07-b2b6-dad6b26cc4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = df.copy()\n",
    "ddf['combined'] = df['VSL_ID'].astype(str) + '_' + df['WAITING_START'].astype(str)\n",
    "oorigin = rr.copy()\n",
    "oorigin['combined'] = oorigin['VSL_ID'].astype(str) + '_' + oorigin['VSL_TIMESTAMP'].astype(str)\n",
    "oorigin = oorigin[['combined','VSL_DRAFT','VSL_SPEED','FROM_PORT_CD']]\n",
    "oorigin = oorigin.rename(columns={'VSL_DRAFT': 'START_DRAFT','VSL_SPEED':'START_SPEED'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55038feb-4470-469f-8325-5a4807c3b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "just_start = pd.merge(ddf,oorigin,on='combined',how='left')\n",
    "just_start.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153aacc-b1b7-4cac-a72c-68d695c691f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 선박명과 trip값을 가진 경우가 존재하는지 파악 함 \n",
    "for ship, ship_df in just_start.groupby('VSL_ID'): \n",
    "    for trip, trip_df in ship_df.groupby('TRIP'): \n",
    "        if trip_df.shape[0] >=2: \n",
    "            print(trip)\n",
    "            display(trip_df)\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da193eb4-e34c-49a5-9c32-098f62a1d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = df.copy()\n",
    "ddf.loc[:,'combined'] = df['VSL_ID'].astype(str) + '_' + df['WAITING_START'].astype(str)\n",
    "oorigin2 = rr.copy()\n",
    "oorigin2.loc[:,'combined'] = oorigin2['VSL_ID'].astype(str) + '_' + oorigin2['VSL_TIMESTAMP'].astype(str)\n",
    "oorigin2 = oorigin2[['combined','VSL_DRAFT','VSL_SPEED']]\n",
    "oorigin2 = oorigin2.rename(columns={'VSL_DRAFT': 'END_DRAFT','VSL_SPEED':'END_SPEED'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066c281-0815-490a-af3e-ade1fa8d7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = pd.merge(just_start,oorigin2,on='combined',how='left')\n",
    "last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386601e-5505-43fe-a40c-60f11eee3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 선박명과 trip값을 가진 경우가 존재하는지 파악 함 \n",
    "for ship, ship_df in last.groupby('VSL_ID'): \n",
    "    for trip, trip_df in ship_df.groupby('TRIP'): \n",
    "        if trip_df.shape[0] >=2: \n",
    "            print(trip)\n",
    "            display(trip_df)\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8e653-5cbb-483b-b5dd-9ec1576acb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = last[['FROM_PORT_CD', 'TO_PORT_CD', 'VSL_ID', 'TRIP', 'WAITING_TIME(H:M:S)', 'WAIT_LAT','WAIT_LON',\n",
    "              'WAITING_START', 'START_LAT', 'START_LON', 'START_WAVE(m)','START_WIND(kn)', 'START_CURRENT(kn)',\n",
    "              'START_HEIGHT', 'START_DRAFT', 'START_SPEED',\n",
    "              'WAITING_END', 'END_LAT', 'END_LON', 'END_WAVE(m)', 'END_WIND(kn)', 'END_CURRENT(kn)',\n",
    "              'END_HEIGHT', 'END_DRAFT', 'END_SPEED']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38cab2f-66d7-42b1-a5fa-b3c9d71a610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved.to_csv('0612_data_add_before_add_ship_info.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773ae38-75b0-464f-a10f-0894b636298a",
   "metadata": {},
   "source": [
    "## 최종 파일 정보 파악 및 정리 (김묘경) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2639bd-c53b-4095-a1b7-6484558cdc91",
   "metadata": {},
   "source": [
    "### 드래프트 결측치  제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6748f-99f0-4043-beca-0a2c21032092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "df = pd.read_csv('0612_data_add_before_add_ship_info.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9afd5-af6b-437b-854f-c2bea10b9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_d_na = df[df['START_DRAFT']!=999]\n",
    "drop_d_na = drop_d_na[drop_d_na['END_DRAFT']!=999]\n",
    "drop_d_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d41cf-297d-4bf4-8cd4-a992179a85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TO_PORT_CD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ffbf3-f385-4253-aa9a-4a6e134f175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_d_na.to_csv('0612_1059_drop_draft_nan.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09875f-afcb-4529-be80-0ff25f272f80",
   "metadata": {},
   "source": [
    "### 해류 결측치 파악 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd2d06-0f14-4f89-8af7-2d537cca39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_to_add_weather1 = drop_d_na[drop_d_na['START_CURRENT(kn)']==-1]\n",
    "need_to_add_weather2 = drop_d_na[drop_d_na['END_CURRENT(kn)']==-1]\n",
    "need_to_add_weather = pd.concat([need_to_add_weather1,need_to_add_weather2],ignore_index=True) \n",
    "need_to_add_weather.drop_duplicates(inplace=True) \n",
    "need_to_add_weather.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a01e0-b98b-4945-bcf4-955db586c511",
   "metadata": {},
   "source": [
    "### 드래프트 결측치를 제거한 파일에 선박 정보 결합 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7b958-cb47-4ea8-9d90-a0bd0b118102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "ais = pd.read_csv('0612_1059_drop_draft_nan.csv')\n",
    "print(ais.shape)\n",
    "ship = pd.read_csv('ais_for_waiting_area_vsl_info.csv')\n",
    "print(ship.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacf3d9-302b-43a0-bda6-b6a6fac596a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_n = ship[['VSL_ID','SHIP_TYPE','VSL_LENGTH','VSL_WIDTH','GROSS_TONNAGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe7d13-9a79-4285-a640-c19e9efe0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(ais,ship_n,how='left') \n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b3fc2-a13e-41a1-9060-b7f847917b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv('0612_before_add_-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7685748-4041-4c2c-a32b-cd30423a3148",
   "metadata": {},
   "source": [
    "## 분담하여 결측치를 채운 정보를 결합, 해류 결측 제거 및 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e78180-3b02-4a22-8663-7561f5b34def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_df = pd.read_csv('0612_before_add_-1.csv') \n",
    "print(data_df.shape)\n",
    "\n",
    "a1 = pd.read_excel('0612_1(수정).xlsx')\n",
    "print(a1.shape)\n",
    "b2 = pd.read_excel('0612_2(수정).xlsx')\n",
    "print(b2.shape)\n",
    "c3 = pd.read_excel('0612_3(수정).xlsx')\n",
    "print(c3.shape)\n",
    "d4 = pd.read_excel('0612_4(수정).xlsx')\n",
    "print(d4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd66163-2540-432f-9fa9-d5ed2d3afc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data_df[data_df['START_CURRENT(kn)']!=-1]\n",
    "temp = temp[temp['END_CURRENT(kn)']!=-1]\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2c5e2-ef6b-4376-93c5-c6b32dafc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('0613_all_data_last.xlsx',index=False)\n",
    "df.to_csv('0613_all_data_last.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc46043-71e1-4b09-b486-8fdd32703d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['TO_PORT_CD']=='KRPUS'].to_csv('0613_all_data_KRPUS.csv')\n",
    "df[df['TO_PORT_CD']=='SGSIN'].to_csv('0613_all_data_SGSIN.csv')\n",
    "df[df['TO_PORT_CD']=='KRBNP'].to_csv('0613_all_data_KRBNP.csv')\n",
    "df[df['TO_PORT_CD']=='HKHKG'].to_csv('0613_all_data_HKHKG.csv')\n",
    "df[df['TO_PORT_CD']=='CNSHA'].to_csv('0613_all_data_CNSHA.csv')\n",
    "df[df['TO_PORT_CD']=='KRINC'].to_csv('0613_all_data_KRINC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904132ca-367d-4064-a03b-9355a878c8b0",
   "metadata": {},
   "source": [
    "# 실질적 대기 지역 추출 (김정수) \n",
    "- 대기 지역 기준: 도착항 위·경도 기준 반경 (± 1.1)도 이내의 범위에서 속도가 3노트 이하로 가장 긴 시간 동안 유지된 구간을 실질적인 대기 구간으로 간주한다.\n",
    "- 분석 절차: 한 번의 항해에 대해 도착항 근처에서 발생한 대기 기록 중 최장 시간 대기한 경우를 찾아 좌표를 추출한다.\n",
    "- 최종 목표: 대기지역 좌표기반 군집화 및 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc213b2-e14e-44ef-bb25-56ff517f44c5",
   "metadata": {},
   "source": [
    "## 필수 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a8c23-ac16-4885-a17b-e795fb42a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cbfd6-c6ab-48d0-a0cd-d237022d3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도착항 위·경도 좌표\n",
    "port_coordinates = {\n",
    "    'SGSIN': (1.2392, 103.8325),\n",
    "    'CNSHA': (31.4001, 121.4971),\n",
    "    'KRPUS': (35.1060, 129.0840),\n",
    "    'KRBNP': (35.0778, 128.7911),\n",
    "    'HKHKG': (22.3360, 114.1240),\n",
    "    'KRINC': (37.4460, 126.6460)\n",
    "}\n",
    "\n",
    "# 위·경도 (± 1.1)도 이내 데이터 추출 함수\n",
    "def vsl_in_radius(df, lat, lon, radius=1.1):\n",
    "    filtered_df=df[(df['LAT']>=lat-radius)&(df['LAT']<=lat+radius)&\n",
    "                    (df['LON']>=lon-radius)&(df['LON']<=lon+radius)]\n",
    "    return filtered_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98493ce7-c443-448f-b41c-4cf96382d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항구별 데이터 로드\n",
    "files = {\n",
    "    'SGSIN': '2.2_SGSIN_drop_outlier.csv',\n",
    "    'CNSHA': '2.2_CNSHA_drop_outlier.csv',\n",
    "    'KRPUS': '2.2_KRPUS_drop_outlier.csv',\n",
    "    'KRBNP': '2.2_KRBNP_drop_outlier.csv',\n",
    "    'HKHKG': '2.2_HKHKG_drop_outlier.csv',\n",
    "    'KRINC': '2.2_KRINC_drop_outlier.csv'\n",
    "}\n",
    "\n",
    "df_by_port_list = {}\n",
    "for port_code, file in files.items():\n",
    "        df_by_port_list[port_code] = pd.read_csv(f'{file}')\n",
    "\n",
    "# VSL_TIMESTAMP 데이터 타입 변경 및 위도 경도 필터링\n",
    "for port_code, df_by_port in df_by_port_list.items():\n",
    "    df_by_port['VSL_TIMESTAMP'] = pd.to_datetime(df_by_port['VSL_TIMESTAMP'])\n",
    "    lat, lon = port_coordinates[port_code]\n",
    "    df_by_port = vsl_in_radius(df_by_port, lat, lon)\n",
    "    df_by_port_list[port_code] = df_by_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c68d8f-d5b3-44fa-abd7-d890894c405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항구별로 반복\n",
    "all_waiting_data = []\n",
    "\n",
    "for port_code, df in df_by_port_list.items():\n",
    "    # 선박별로 그룹화\n",
    "    grouped_by_vsl = df.groupby('VSL_ID')\n",
    "    \n",
    "    # 항해(TRIP)별로 다시 그룹화해서 df_port에 담기\n",
    "    df_list = []\n",
    "    for vsl_id, vsl_group in grouped_by_vsl:\n",
    "        grouped_by_trip = vsl_group.groupby('TRIP')\n",
    "        for trip_id, trip_group in grouped_by_trip:\n",
    "            df_list.append(trip_group)\n",
    "    df_port = pd.concat(df_list)\n",
    "    # TIMESTAMP의 역순으로 데이터프레임을 정렬\n",
    "    df_port['VSL_TIMESTAMP'] = pd.to_datetime(df_port['VSL_TIMESTAMP'])\n",
    "    df_port = df_port.sort_values(by=['VSL_ID', 'TRIP', 'VSL_TIMESTAMP'], ascending=[True, True, False])\n",
    "    \n",
    "    # 대기 구간을 산출하고 새로운 컬럼에 담기\n",
    "    waiting_data = []\n",
    "    for vsl_id, vsl_group in df_port.groupby('VSL_ID'):\n",
    "        for trip_id, trip_group in vsl_group.groupby('TRIP'):\n",
    "            trip_group = trip_group.reset_index(drop=True)\n",
    "            waiting_order = 0\n",
    "            waiting_start = None\n",
    "            lat, lon = None, None\n",
    "            for i in range(len(trip_group)):\n",
    "                if trip_group.loc[i, 'VSL_SPEED'] <= 3:\n",
    "                    if waiting_start is None:\n",
    "                        waiting_start=trip_group.loc[i, 'VSL_TIMESTAMP']\n",
    "                        start_lat=trip_group.loc[i, 'LAT']\n",
    "                        start_lon=trip_group.loc[i, 'LON']\n",
    "                    waiting_end=trip_group.loc[i, 'VSL_TIMESTAMP']\n",
    "                    end_lat=trip_group.loc[i, 'LAT']\n",
    "                    end_lon=trip_group.loc[i, 'LON']\n",
    "                    draft=trip_group.loc[i,'VSL_DRAFT']\n",
    "                else:\n",
    "                    if waiting_start is not None:\n",
    "                        waiting_order += 1\n",
    "                        waiting_time=waiting_start-waiting_end\n",
    "                        waiting_data.append({\n",
    "                            'VSL_ID': vsl_id,\n",
    "                            'TRIP': trip_id,\n",
    "                            'WAITING_ORDER': waiting_order,\n",
    "                            'WAITING_START': waiting_end,\n",
    "                            'WAITING_END': waiting_start,\n",
    "                            'WAITING_TIME(H:M:S)': waiting_time,\n",
    "                            'START_LAT': end_lat,\n",
    "                            'START_LON': end_lon,\n",
    "                            'END_LAT': start_lat,\n",
    "                            'END_LON': start_lon,\n",
    "                            'TO_PORT_CD': port_code,\n",
    "                            'DRAFT':draft\n",
    "                        })\n",
    "                        waiting_start = None\n",
    "                        start_lat, start_lon = None, None\n",
    "                        end_lat, end_lon = None, None\n",
    "            if waiting_start is not None:\n",
    "                waiting_order += 1\n",
    "                waiting_time=waiting_start-waiting_end\n",
    "                waiting_data.append({\n",
    "                    'VSL_ID': vsl_id,\n",
    "                    'TRIP': trip_id,\n",
    "                    'WAITING_ORDER': waiting_order,\n",
    "                    'WAITING_START': waiting_end,\n",
    "                    'WAITING_END': waiting_start,\n",
    "                    'WAITING_TIME(H:M:S)': waiting_time,\n",
    "                    'START_LAT': end_lat,\n",
    "                    'START_LON': end_lon,\n",
    "                    'END_LAT': start_lat,\n",
    "                    'END_LON': start_lon,\n",
    "                    'TO_PORT_CD': port_code,\n",
    "                    'DRAFT':draft,\n",
    "                })\n",
    "\n",
    "    waiting_df = pd.DataFrame(waiting_data)\n",
    "    all_waiting_data.append(waiting_df)\n",
    "    # print(waiting_df['TO_PORT_CD'].unique())\n",
    "    # print(waiting_df.info())\n",
    "    # print('='*100)\n",
    "\n",
    "# 모든 항구의 대기 데이터 통합 및 저장\n",
    "final_waiting_df = pd.concat(all_waiting_data, ignore_index=True)\n",
    "final_waiting_df = final_waiting_df[final_waiting_df['DRAFT'] != 999]\n",
    "# print(final_waiting_df.info())\n",
    "# display(final_waiting_df.head(1))\n",
    "# final_waiting_df.to_csv('ACTUAL_WAITING_drop_outliers.csv', index=False)\n",
    "\n",
    "final_waiting_df.to_csv('final_waiting_with_draft.csv', index=False)\n",
    "print(\"END\")\n",
    "# final_waiting_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa3ab9-b09d-4354-9554-47a04be7c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_waiting_df = final_waiting_df[final_waiting_df['DRAFT'] != 999]\n",
    "final_waiting_df\n",
    "# final_waiting_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164fb120-3751-42bd-befe-b1cf17272de3",
   "metadata": {},
   "source": [
    "## 실질 대기에 대한 기술 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b383e6-8d76-4016-9881-9730d890a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_waiting_df['WAITING_TIME_SECONDS'] = final_waiting_df['WAITING_TIME(H:M:S)'].apply(lambda x: pd.to_timedelta(x).total_seconds())\n",
    "\n",
    "idx = final_waiting_df.groupby(['VSL_ID', 'TRIP'])['WAITING_TIME_SECONDS'].idxmax()\n",
    "actual_waiting_df = final_waiting_df.loc[idx]\n",
    "\n",
    "describe_actual_waiting = actual_waiting_df.groupby('TO_PORT_CD').agg({\n",
    "    'WAITING_TIME_SECONDS': ['mean', 'min', 'max','median']\n",
    "}).reset_index()\n",
    "\n",
    "describe_actual_waiting.columns = ['TO_PORT_CD', 'AVG_ACTUAL_WAITING_TIME', 'MIN_WAITING_TIME', 'MAX_WAITING_TIME','MEDIAN_WAITING_TIME']\n",
    "\n",
    "describe_actual_waiting['AVG_ACTUAL_WAITING_TIME'] = pd.to_timedelta(describe_actual_waiting['AVG_ACTUAL_WAITING_TIME'], unit='s')\n",
    "describe_actual_waiting['MIN_WAITING_TIME'] = pd.to_timedelta(describe_actual_waiting['MIN_WAITING_TIME'], unit='s')\n",
    "describe_actual_waiting['MAX_WAITING_TIME'] = pd.to_timedelta(describe_actual_waiting['MAX_WAITING_TIME'], unit='s')\n",
    "describe_actual_waiting['MEDIAN_WAITING_TIME'] = pd.to_timedelta(describe_actual_waiting['MEDIAN_WAITING_TIME'], unit='s')\n",
    "\n",
    "# describe_actual_waiting.to_csv('DESCRIBE_actual_waiting.csv_drop_outliers.csv', index=False)\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f03aa5-91b8-4cdb-9445-326285093070",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_actual_waiting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486b448-a78c-48ae-81eb-455f41ba8517",
   "metadata": {},
   "source": [
    "# 군집화를 위한 데이터프레임 생성 (김정수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0dd1e5-e011-4d5a-8902-563c4f382ded",
   "metadata": {},
   "source": [
    "## 원데이터에서 실질 대기 구역 내 모든 좌표 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b208b0-30e5-435d-85fb-72a2a685f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'SGSIN': '2.2_SGSIN_drop_outlier.csv',\n",
    "    'CNSHA': '2.2_CNSHA_drop_outlier.csv',\n",
    "    'KRPUS': '2.2_KRPUS_drop_outlier.csv',\n",
    "    'KRBNP': '2.2_KRBNP_drop_outlier.csv',\n",
    "    'HKHKG': '2.2_HKHKG_drop_outlier.csv',\n",
    "    'KRINC': '2.2_KRINC_drop_outlier.csv'\n",
    "}\n",
    "\n",
    "df_by_port = {port_code: pd.read_csv(file) for port_code, file in files.items()}\n",
    "for port_code, df in df_by_port.items():\n",
    "    df['VSL_TIMESTAMP'] = pd.to_datetime(df['VSL_TIMESTAMP'])\n",
    "final_waiting_df = pd.read_csv('ACTUAL_WAITING_drop_outliers.csv', parse_dates=['WAITING_START', 'WAITING_END'])\n",
    "\n",
    "# 실질 대기 구간 산출\n",
    "final_waiting_df['WAITING_TIME_SECONDS']=final_waiting_df['WAITING_TIME(H:M:S)'].apply(lambda x: pd.to_timedelta(x).total_seconds()) # 비교를 위해 대기 시간 컬럼을 초단위로 통일\n",
    "idx = final_waiting_df.groupby(['VSL_ID', 'TRIP'])['WAITING_TIME_SECONDS'].idxmax() # 최장 대기 구간이 actual_waiting임.\n",
    "actual_waiting_df = final_waiting_df.loc[idx] # 최장대기 구간의 인덱스를 가져오기\n",
    "\n",
    "coords_in_actual_waiting = [] # 원데이터에서 데이터 가져와 담을 리스트 생성\n",
    "for port_code, port_df in df_by_port.items(): # 항구코드, 항구별 데이터\n",
    "    # 대기 추출 데이터프레임에서 항구별 데이터 호출\n",
    "    actual_waiting_subset=actual_waiting_df[actual_waiting_df['TO_PORT_CD']==port_code]\n",
    "    # 행값 추출\n",
    "    for _, row in actual_waiting_subset.iterrows():\n",
    "        vsl_id=row['VSL_ID']\n",
    "        waiting_time = row['WAITING_TIME(H:M:S)']\n",
    "        draft=row['DRAFT']\n",
    "        trip_id=row['TRIP']\n",
    "        waiting_start=row['WAITING_START']\n",
    "        waiting_end=row['WAITING_END']\n",
    "        # 원데이터에서 실질 대기 구간 내 'TO_PORT_CD','VSL_TIMESTAMP', 'LAT', 'LON' 값 가져오기.\n",
    "        records_in_actual_waiting=port_df[(port_df['VSL_ID']==vsl_id)&(port_df['TRIP']==trip_id)\n",
    "                                &(port_df['VSL_TIMESTAMP']>=waiting_start)&(port_df['VSL_TIMESTAMP'] <= waiting_end)][['TO_PORT_CD','VSL_ID','TRIP','VSL_TIMESTAMP', 'LAT', 'LON']]\n",
    "        records_in_actual_waiting['VSL_ID'] = vsl_id\n",
    "        records_in_actual_waiting['WAITING_TIME'] = waiting_time\n",
    "        records_in_actual_waiting['DRAFT']=draft\n",
    "        coords_in_actual_waiting.append(records_in_actual_waiting)\n",
    "\n",
    "coords_in_actual_waiting_df=pd.concat(coords_in_actual_waiting).reset_index(drop=True)\n",
    "coords_in_actual_waiting_df['WAITING_TIME'] = pd.to_timedelta(coords_in_actual_waiting_df['WAITING_TIME'])\n",
    "coords_in_actual_waiting_df.to_csv('ALL_COORDS_in_actual_waiting_with_draft.csv', index=False)\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a46cd5-9dbb-4486-ac1b-d8e9d3819979",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'SGSIN': '2.2_SGSIN_drop_outlier.csv',\n",
    "    'CNSHA': '2.2_CNSHA_drop_outlier.csv',\n",
    "    'KRPUS': '2.2_KRPUS_drop_outlier.csv',\n",
    "    'KRBNP': '2.2_KRBNP_drop_outlier.csv',\n",
    "    'HKHKG': '2.2_HKHKG_drop_outlier.csv',\n",
    "    'KRINC': '2.2_KRINC_drop_outlier.csv'\n",
    "}\n",
    "\n",
    "df_by_port = {port_code: pd.read_csv(file) for port_code, file in files.items()}\n",
    "for port_code, df in df_by_port.items():\n",
    "    df['VSL_TIMESTAMP'] = pd.to_datetime(df['VSL_TIMESTAMP'])\n",
    "final_waiting_df = pd.read_csv('final_waiting_with_draft.csv', parse_dates=['WAITING_START', 'WAITING_END'])\n",
    "\n",
    "# 실질 대기 구간 산출\n",
    "final_waiting_df['WAITING_TIME_SECONDS']=final_waiting_df['WAITING_TIME(H:M:S)'].apply(lambda x: pd.to_timedelta(x).total_seconds()) # 비교를 위해 대기 시간 컬럼을 초단위로 통일\n",
    "idx = final_waiting_df.groupby(['VSL_ID', 'TRIP'])['WAITING_TIME_SECONDS'].idxmax() # 최장 대기 구간이 actual_waiting임.\n",
    "actual_waiting_df = final_waiting_df.loc[idx] # 최장대기 구간의 인덱스를 가져오기\n",
    "\n",
    "coords_in_actual_waiting = [] # 원데이터에서 데이터 가져와 담을 리스트 생성\n",
    "for port_code, port_df in df_by_port.items(): # 항구코드, 항구별 데이터\n",
    "    # 대기 추출 데이터프레임에서 항구별 데이터 호출\n",
    "    actual_waiting_subset=actual_waiting_df[actual_waiting_df['TO_PORT_CD']==port_code]\n",
    "    # 행값 추출\n",
    "    for _, row in actual_waiting_subset.iterrows():\n",
    "        vsl_id=row['VSL_ID']\n",
    "        waiting_time = row['WAITING_TIME(H:M:S)']\n",
    "        draft=row['DRAFT']\n",
    "        trip_id=row['TRIP']\n",
    "        waiting_start=row['WAITING_START']\n",
    "        waiting_end=row['WAITING_END']\n",
    "        # 원데이터에서 실질 대기 구간 내 'TO_PORT_CD','VSL_TIMESTAMP', 'LAT', 'LON' 값 가져오기.\n",
    "        records_in_actual_waiting=port_df[(port_df['VSL_ID']==vsl_id)&(port_df['TRIP']==trip_id)\n",
    "                                &(port_df['VSL_TIMESTAMP']>=waiting_start)&(port_df['VSL_TIMESTAMP'] <= waiting_end)][['TO_PORT_CD','VSL_ID','TRIP','VSL_TIMESTAMP', 'LAT', 'LON']]\n",
    "        records_in_actual_waiting['VSL_ID'] = vsl_id\n",
    "        records_in_actual_waiting['WAITING_TIME'] = waiting_time\n",
    "        records_in_actual_waiting['DRAFT']=draft\n",
    "        coords_in_actual_waiting.append(records_in_actual_waiting)\n",
    "\n",
    "coords_in_actual_waiting_df=pd.concat(coords_in_actual_waiting).reset_index(drop=True)\n",
    "coords_in_actual_waiting_df['WAITING_TIME'] = pd.to_timedelta(coords_in_actual_waiting_df['WAITING_TIME'])\n",
    "coords_in_actual_waiting_df.to_csv('ALL_COORDS_in_actual_waiting_with_draft.csv', index=False)\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a043fd-b600-4145-8366-051d4c45ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv('ALL_COORDS_in_actual_waiting_with_draft.csv')\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff089d16-718f-4cb0-b112-6ce419c7ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'SGSIN': '2.2_SGSIN_drop_outlier.csv',\n",
    "    'CNSHA': '2.2_CNSHA_drop_outlier.csv',\n",
    "    'KRPUS': '2.2_KRPUS_drop_outlier.csv',\n",
    "    'KRBNP': '2.2_KRBNP_drop_outlier.csv',\n",
    "    'HKHKG': '2.2_HKHKG_drop_outlier.csv',\n",
    "    'KRINC': '2.2_KRINC_drop_outlier.csv'\n",
    "}\n",
    "\n",
    "df_by_port = {port_code: pd.read_csv(file) for port_code, file in files.items()}\n",
    "for port_code, df in df_by_port.items():\n",
    "    df['VSL_TIMESTAMP'] = pd.to_datetime(df['VSL_TIMESTAMP'])\n",
    "\n",
    "# 'VSL_DRAFT'를 제외하고 날짜 형식의 열을 지정\n",
    "final_waiting_df = pd.read_csv('final_waiting_with_draft.csv', parse_dates=['WAITING_START', 'WAITING_END'])\n",
    "\n",
    "# 실질 대기 구간 산출\n",
    "final_waiting_df['WAITING_TIME_SECONDS'] = final_waiting_df['WAITING_TIME(H:M:S)'].apply(lambda x: pd.to_timedelta(x).total_seconds())  # 비교를 위해 대기 시간 컬럼을 초단위로 통일\n",
    "idx = final_waiting_df.groupby(['VSL_ID', 'TRIP'])['WAITING_TIME_SECONDS'].idxmax()  # 최장 대기 구간이 actual_waiting임.\n",
    "actual_waiting_df = final_waiting_df.loc[idx]  # 최장대기 구간의 인덱스를 가져오기\n",
    "\n",
    "coords_in_actual_waiting = []  # 원데이터에서 데이터 가져와 담을 리스트 생성\n",
    "for port_code, port_df in df_by_port.items():  # 항구코드, 항구별 데이터\n",
    "    # 대기 추출 데이터프레임에서 항구별 데이터 호출\n",
    "    actual_waiting_subset = actual_waiting_df[actual_waiting_df['TO_PORT_CD'] == port_code]\n",
    "    # 행값 추출\n",
    "    for _, row in actual_waiting_subset.iterrows():\n",
    "        vsl_id = row['VSL_ID']\n",
    "        waiting_time = row['WAITING_TIME(H:M:S)']\n",
    "        draft = row['DRAFT']\n",
    "        trip_id = row['TRIP']\n",
    "        waiting_start = row['WAITING_START']\n",
    "        waiting_end = row['WAITING_END']\n",
    "        # 원데이터에서 실질 대기 구간 내 'TO_PORT_CD','VSL_TIMESTAMP', 'LAT', 'LON' 값 가져오기.\n",
    "        records_in_actual_waiting = port_df[\n",
    "            (port_df['VSL_ID'] == vsl_id) & (port_df['TRIP'] == trip_id)\n",
    "            & (port_df['VSL_TIMESTAMP'] >= waiting_start) & (port_df['VSL_TIMESTAMP'] <= waiting_end)\n",
    "        ][['TO_PORT_CD', 'VSL_ID', 'TRIP', 'VSL_TIMESTAMP', 'LAT', 'LON']]\n",
    "        records_in_actual_waiting['VSL_ID'] = vsl_id\n",
    "        records_in_actual_waiting['WAITING_TIME'] = waiting_time\n",
    "        records_in_actual_waiting['DRAFT'] = draft\n",
    "        coords_in_actual_waiting.append(records_in_actual_waiting)\n",
    "\n",
    "coords_in_actual_waiting_df = pd.concat(coords_in_actual_waiting).reset_index(drop=True)\n",
    "coords_in_actual_waiting_df['WAITING_TIME'] = pd.to_timedelta(coords_in_actual_waiting_df['WAITING_TIME'])\n",
    "coords_in_actual_waiting_df.to_csv('ALL_COORDS_in_actual_waiting_with_draft.csv', index=False)\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c20f9-5508-48cb-bc4d-0d4dfdfd5266",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pd.read_csv('ACTUAL_WAITING_drop_outliers.csv')\n",
    "s.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b89701-2e4c-4776-a68a-4f859fc82aec",
   "metadata": {},
   "source": [
    "# 대기 기간 내 중앙 좌표 추출하기 (곽현수, 유지민)\n",
    "- 실질 대기 구역 ais 신호들을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37816f5-5daf-4f37-8377-d555c5e0e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# 경고 메시지 필터링 설정\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d0f7c-5a1b-4ae0-b1dd-09bb3d6f4088",
   "metadata": {},
   "source": [
    "## 중앙 좌표 추출 (유지민) \n",
    "- 신호 데이터\n",
    "- 1개 : 해당 좌표 return\n",
    "- 2개 : 둘의 평균 좌표 return\n",
    "- 3개 이상 : 해당 지점들의 중앙 좌표를 kmeans를 이요해 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6f294-0bee-412f-b082-525e2d890f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WAITING_POINT(wait_df):\n",
    "    record = wait_df.shape[0]\n",
    "    if record == 1:\n",
    "        latitude = wait_df['LAT']\n",
    "        longitude = wait_df['LON']\n",
    "        return (latitude, longitude)\n",
    "    elif record == 2:\n",
    "        mid_lat = (wait_df.iloc[0]['LAT'] + wait_df.iloc[0]['LAT']) / 2\n",
    "        mid_lon = (wait_df.iloc[1]['LON'] + wait_df.iloc[1]['LON']) / 2\n",
    "        return (mid_lat, mid_lon)\n",
    "    elif record >= 3:\n",
    "        # KMeans 클러스터링 수행 (클러스터 수 K=1)\n",
    "        data = wait_df[['LAT','LON']].to_numpy()\n",
    "        kmean = KMeans(n_clusters=1, random_state=0)\n",
    "        kmean.fit(data)\n",
    "        # 중심점 추출\n",
    "        center = kmean.cluster_centers_\n",
    "        center_lat = center[0][0]\n",
    "        center_lon = center[0][1]\n",
    "        return (center_lat, center_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7078f95-2860-4e15-83a0-0b9250f94a99",
   "metadata": {},
   "source": [
    "## 실제 파일에 적용 (곽현수) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb96428-164a-4a7e-8e39-ca677fd8eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2.2_drop_outlier_waiting_before_arrive.csv.csv')\n",
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202b50c-5eaf-4538-84f6-f6c230eff857",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_new_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "grouped_vsl = df.groupby('VSL_ID')\n",
    "\n",
    "for vsl_id, group_vsl in grouped_vsl:\n",
    "    grouped_trip = group_vsl.groupby('TRIP')\n",
    "    for trip, group_trip in grouped_trip:\n",
    "        \n",
    "        coordinates = WAITING_POINT(group_trip)\n",
    "        \n",
    "        # 함수에서 도출한 좌표값을 function_new_df의 새로운 컬럼에 추가\n",
    "        group_trip['WAIT_LAT'] = coordinates[0]\n",
    "        group_trip['WAIT_LON'] = coordinates[1]\n",
    "        \n",
    "        function_new_df = pd.concat([function_new_df, group_trip], ignore_index=True)\n",
    "        \n",
    "print(function_new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41d5de-f527-4bd6-a036-e666cefe7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(function_new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2b86b-bc92-4642-9e4c-16a10e7e9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_new_df.to_csv('function_new_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
